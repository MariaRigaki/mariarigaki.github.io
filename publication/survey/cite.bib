@article{10.1145/3624010,
author = {Rigaki, Maria and Garcia, Sebastian},
title = {A Survey of Privacy Attacks in Machine Learning},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3624010},
doi = {10.1145/3624010},
abstract = {As machine learning becomes more widely used, the need to study its implications in security and privacy becomes more urgent. Although the body of work in privacy has been steadily growing over the past few years, research on the privacy aspects of machine learning has received less focus than the security aspects. Our contribution in this research is an analysis of more than 45 papers related to privacy attacks against machine learning that have been published during the past seven years. We propose an attack taxonomy, together with a threat model that allows the categorization of different attacks based on the adversarial knowledge, and the assets under attack. An initial exploration of the causes of privacy leaks is presented, as well as a detailed analysis of the different attacks. Finally, we present an overview of the most commonly proposed defenses and a discussion of the open problems and future directions identified during our analysis.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = {sep},
keywords = {machine learning, model inversion, model extraction, membership inference, privacy, reconstruction, property inference}
}