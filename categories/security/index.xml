<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Security on Maria Rigaki</title>
    <link>https://mariarigaki.github.io/categories/security/</link>
    <description>Recent content in Security on Maria Rigaki</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Nov 2019 20:17:04 +0100</lastBuildDate>
    
	    <atom:link href="https://mariarigaki.github.io/categories/security/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Changing Weights and Biases Programmatically for “Neural Network Hacking” and more</title>
      <link>https://mariarigaki.github.io/post/hacking-nn-programmatically/</link>
      <pubDate>Fri, 29 Nov 2019 20:17:04 +0100</pubDate>
      
      <guid>https://mariarigaki.github.io/post/hacking-nn-programmatically/</guid>
      <description>&lt;p&gt;&lt;strong&gt;TL;DR Using Tensorflow / Keras APIs to read and change Neural Network parameters.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A few days ago I came across a paper called &lt;a href=&#34;https://arxiv.org/pdf/1911.07658.pdf&#34;&gt;“Hacking Neural Networks”&lt;/a&gt; by Michael Kissner aka &lt;a href=&#34;https://twitter.com/Spellwrath&#34;&gt;@Spellwrath&lt;/a&gt;. It is a beautiful introduction to attacks against neural networks, very approachable and fun to read. What I liked most is that it comes together with a Github repository and some exercises to try the different attacks: &lt;a href=&#34;https://github.com/Kayzaks/HackingNeuralNetworks&#34;&gt;https://github.com/Kayzaks/HackingNeuralNetworks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The first chapter introduces a simple attack where the main idea is that we want to cause a neural network to misclassify an image by just changing some part of the model. The assumption here is that we have access to the model file and we can change it arbitrarily. The model is saved in the HDF5 format (“model.h5”).  The proposed solution and probably the most straightforward thing to do is to load the model using a tool such as HDFView that can edit the file and change it manually. But what if we want to do this programmatically?&lt;/p&gt;
&lt;p&gt;Tensorflow and keras provide this possibility, however, the documentation is not the easiest to navigate. Here is how you could solve the exercises 0-0 and 0-1 programmatically. Note, that the code below works for Tensorflow v.2.0.&lt;/p&gt;
&lt;p&gt;First, the necessary imports:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; tf
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; tensorflow &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; keras
&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#f92672&#34;&gt;as&lt;/span&gt; np
&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; skimage &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;This part of the code is provided in the exercise code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Load the Image File with skimage.&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# (&amp;#39;imread&amp;#39; was deprecated in SciPy 1.0.0, and will be removed in 1.2.0.)&lt;/span&gt;
image &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; io&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;imread(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;./fake_id.png&amp;#39;&lt;/span&gt;)
processedImage &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros([&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;])
&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; yy &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;):
   &lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; xx &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;28&lt;/span&gt;):
       processedImage[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;][xx][yy][&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; float(image[xx][yy]) &lt;span style=&#34;color:#f92672&#34;&gt;/&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;255&lt;/span&gt;
 
&lt;span style=&#34;color:#75715e&#34;&gt;# Load the Model&lt;/span&gt;
model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;load_model(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;./model.h5&amp;#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The first exercise is asking us to answer a few basic questions and the first one is “What does the architecture look like?” We can get this information by simply calling &lt;code&gt;model.summary()&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Answer to Q1&lt;/span&gt;
model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which provides the following print out:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-Model:&#34; data-lang=&#34;Model:&#34;&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 12, 12, 64)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 9216)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               1179776   
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 10)                1290      
=================================================================
Total params: 1,199,882
Trainable params: 1,199,882
Non-trainable params: 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The second question is “What was the model trained with?” and it refers to the optimizer that was used. This can also be easily retrieved using the model.optimizer variable:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Answer to Q2&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;get_config())
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;which prints the following output:
&lt;code&gt;{&#39;name&#39;: &#39;Adadelta&#39;, &#39;learning_rate&#39;: 1.0, &#39;decay&#39;: 0.0, &#39;rho&#39;: 0.95, &#39;epsilon&#39;: 1e-07}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;According to the printout the optimizer used is Adadelta and we can also see the initial configuration values set.&lt;/p&gt;
&lt;p&gt;The second exercise asks us to cause misclassification of a specific image given as input. The input is an image of the digit “2” but only an image of digit “4” grants access to a hypothetical system. We need to get the neural network to grant us access without changing the image. The proposed way is to try and change manually the biases at the last layer of the model using a tool. But we can also do this programmatically.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Get all the trainable variables and their values&lt;/span&gt;
&lt;span style=&#34;color:#75715e&#34;&gt;# Feel free to print the tvars variable to see all of them&lt;/span&gt;
tvars &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable_variables
 
&lt;span style=&#34;color:#75715e&#34;&gt;# The biases we want to change are the last item in the list&lt;/span&gt;
bias &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tvars[&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;]
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Values before the change:&amp;#34;&lt;/span&gt;, bias)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Print output:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;Values before the change: &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Variable &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;dense_2/bias:0&amp;#39;&lt;/span&gt; shape&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;,) &lt;span style=&#34;color:#75715e&#34;&gt;#dtype=float32, numpy=&lt;/span&gt;
array([&lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.03398215&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;0.15133834&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.04235273&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.03443589&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.03148068&lt;/span&gt;,
       &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.03133481&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.14359292&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#ae81ff&#34;&gt;0.04240401&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;0.01841561&lt;/span&gt;,  &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0588899&lt;/span&gt; ],
      dtype&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;float32)&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;And now we cChange the value of the bias for number 4 to a large value&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;bias[&lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;assign(&lt;span style=&#34;color:#ae81ff&#34;&gt;100.&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Values after the change:&amp;#34;&lt;/span&gt;, bias)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Values after the change: &amp;lt;tf.Variable &#39;dense_2/bias:0&#39; shape=(10,) dtype=float32, numpy=
array([-3.3982150e-02,  1.5133834e-01, -4.2352729e-02, -3.4435891e-02,
        1.0000000e+02, -3.1334814e-02, -1.4359292e-01, -4.2404007e-02,
        1.8415609e-02,  5.8889896e-02], dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can see that the value for the bias at index 4 has changed to 100.
Now if we run the last part of the code:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Run the Model and check what Digit was shown&lt;/span&gt;
shownDigit &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;argmax(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(processedImage))
&lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Predictions:&amp;#34;&lt;/span&gt;, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;predict(processedImage))
 
&lt;span style=&#34;color:#75715e&#34;&gt;# Only Digit 4 grants access!&lt;/span&gt;
&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; shownDigit &lt;span style=&#34;color:#f92672&#34;&gt;==&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;:
   &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Access Granted&amp;#34;&lt;/span&gt;)
&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:
   &lt;span style=&#34;color:#66d9ef&#34;&gt;print&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Access Denied&amp;#34;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The final printout:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;Predictions: [[&lt;span style=&#34;color:#ae81ff&#34;&gt;1.6611005e-38&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0000000e+00&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;9.0147166e-26&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0000000e+00&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;1.0000000e+00&lt;/span&gt;
  &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0000000e+00&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0000000e+00&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2.3765060e-37&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;6.6040375e-35&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.0000000e+00&lt;/span&gt;]]
Access Granted
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;From the printout we can see that the prediction for value four is equal to 1.0 and all the other values are either zero or extremely small. And of course we get “Access Granted” 😄&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
