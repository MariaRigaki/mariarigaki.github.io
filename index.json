[{"authors":["admin"],"categories":null,"content":"Maria Rigaki is a PhD student in the department of Computer Science at Czech Technical University (CTU) in Prague. As a member of Stratosphere Lab, she is working on security and privacy of Machine Learning as well as applications of AI in cyber security. Before that she spent many years working as a software developer and systems architect. Her work spanned several domains including designing and developing solutions for telecommunications, physical security, emergency response systems and critical infrastructures. In her spare time Maria enjoys hacking and playing CTFs.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://mariarigaki.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Maria Rigaki is a PhD student in the department of Computer Science at Czech Technical University (CTU) in Prague. As a member of Stratosphere Lab, she is working on security and privacy of Machine Learning as well as applications of AI in cyber security. Before that she spent many years working as a software developer and systems architect. Her work spanned several domains including designing and developing solutions for telecommunications, physical security, emergency response systems and critical infrastructures.","tags":null,"title":"","type":"authors"},{"authors":["Maria Rigaki","Sebastian Garcia"],"categories":[],"content":"","date":1595000056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595000056,"objectID":"a63ff5c0a9d30f73b6ddf56f9d164482","permalink":"https://mariarigaki.github.io/publication/privacy-survey/","publishdate":"2020-07-17T17:34:16+02:00","relpermalink":"/publication/privacy-survey/","section":"publication","summary":"As machine learning becomes more widely used, the need to study its implications in security and privacy becomes more urgent. Research on the security aspects of machine learning, such as adversarial attacks, has received a lot of focus and publicity, but privacy related attacks have received less attention from the research community. Although there is a growing body of work in the area, there is yet no extensive analysis of privacy related attacks. To contribute into this research line we analyzed more than 40 papers related to privacy attacks against machine learning that have been published during the past seven years. Based on this analysis, an attack taxonomy is proposed together with a threat model that allows the categorization of the different attacks based on the adversarial knowledge and the assets under attack. In addition, a detailed analysis of the different attacks is presented, including the models under attack and the datasets used, as well as the common elements and main differences between the approaches under the defined threat model. Finally, we explore the potential reasons for privacy leaks and present an overview of the most common proposed defenses.","tags":[],"title":"A Survey of Privacy Attacks in Machine Learning","type":"publication"},{"authors":["Maria Rigaki"],"categories":["Machine Learning","Security"],"content":"TL;DR Using Tensorflow / Keras APIs to read and change Neural Network parameters.\nA few days ago I came across a paper called ‚ÄúHacking Neural Networks‚Äù by Michael Kissner aka @Spellwrath. It is a beautiful introduction to attacks against neural networks, very approachable and fun to read. What I liked most is that it comes together with a Github repository and some exercises to try the different attacks: https://github.com/Kayzaks/HackingNeuralNetworks\nThe first chapter introduces a simple attack where the main idea is that we want to cause a neural network to misclassify an image by just changing some part of the model. The assumption here is that we have access to the model file and we can change it arbitrarily. The model is saved in the HDF5 format (‚Äúmodel.h5‚Äù). The proposed solution and probably the most straightforward thing to do is to load the model using a tool such as HDFView that can edit the file and change it manually. But what if we want to do this programmatically?\nTensorflow and keras provide this possibility, however, the documentation is not the easiest to navigate. Here is how you could solve the exercises 0-0 and 0-1 programmatically. Note, that the code below works for Tensorflow v.2.0.\nFirst, the necessary imports:\nimport tensorflow as tf from tensorflow import keras import numpy as np from skimage import io This part of the code is provided in the exercise code:\n# Load the Image File with skimage. # (\u0026#39;imread\u0026#39; was deprecated in SciPy 1.0.0, and will be removed in 1.2.0.) image = io.imread(\u0026#39;./fake_id.png\u0026#39;) processedImage = np.zeros([1, 28, 28, 1]) for yy in range(28): for xx in range(28): processedImage[0][xx][yy][0] = float(image[xx][yy]) / 255 # Load the Model model = keras.models.load_model(\u0026#39;./model.h5\u0026#39;) The first exercise is asking us to answer a few basic questions and the first one is ‚ÄúWhat does the architecture look like?‚Äù We can get this information by simply calling model.summary():\n# Answer to Q1 model.summary() which provides the following print out:\n_________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 _________________________________________________________________ conv2d_2 (Conv2D) (None, 24, 24, 64) 18496 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64) 0 _________________________________________________________________ dropout_1 (Dropout) (None, 12, 12, 64) 0 _________________________________________________________________ flatten_1 (Flatten) (None, 9216) 0 _________________________________________________________________ dense_1 (Dense) (None, 128) 1179776 _________________________________________________________________ dropout_2 (Dropout) (None, 128) 0 _________________________________________________________________ dense_2 (Dense) (None, 10) 1290 ================================================================= Total params: 1,199,882 Trainable params: 1,199,882 Non-trainable params: 0 The second question is ‚ÄúWhat was the model trained with?‚Äù and it refers to the optimizer that was used. This can also be easily retrieved using the model.optimizer variable:\n# Answer to Q2 print(model.optimizer.get_config()) which prints the following output: {'name': 'Adadelta', 'learning_rate': 1.0, 'decay': 0.0, 'rho': 0.95, 'epsilon': 1e-07}\nAccording to the printout the optimizer used is Adadelta and we can also see the initial configuration values set.\nThe second exercise asks us to cause misclassification of a specific image given as input. The input is an image of the digit ‚Äú2‚Äù but only an image of digit ‚Äú4‚Äù grants access to a hypothetical system. We need to get the neural network to grant us access without changing the image. The proposed way is to try and change manually the biases at the last layer of the model using a tool. But we can also do this programmatically.\n# Get all the trainable variables and their values # Feel free to print the tvars variable to see all of them tvars = model.trainable_variables # The biases we want to change are the last item in the list bias = tvars[-1] print(\u0026#34;Values before the change:\u0026#34;, bias) Print output:\nValues before the change: \u0026lt;tf.Variable \u0026#39;dense_2/bias:0\u0026#39; shape=(10,) #dtype=float32, numpy= array([-0.03398215, 0.15133834, -0.04235273, -0.03443589, -0.03148068, -0.03133481, -0.14359292, -0.04240401, 0.01841561, 0.0588899 ], dtype=float32)\u0026gt; And now we cChange the value of the bias for number 4 to a large value\nbias[4].assign(100.) print(\u0026#34;Values after the change:\u0026#34;, bias) Values after the change: \u0026lt;tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32, numpy= array([-3.3982150e-02, 1.5133834e-01, -4.2352729e-02, -3.4435891e-02, 1.0000000e+02, -3.1334814e-02, -1.4359292e-01, -4.2404007e-02, 1.8415609e-02, 5.8889896e-02], dtype=float32)\u0026gt; We can see that the value for the bias at index 4 has changed to 100. Now if we run the last part of the code:\n# Run the Model and check what Digit was shown shownDigit = np.argmax(model.predict(processedImage)) print(\u0026#34;Predictions:\u0026#34;, model.predict(processedImage)) # Only Digit 4 grants access! if shownDigit == 4: print(\u0026#34;Access Granted\u0026#34;) else: print(\u0026#34;Access Denied\u0026#34;) The final printout:\nPredictions: [[1.6611005e-38 0.0000000e+00 9.0147166e-26 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3765060e-37 6.6040375e-35 0.0000000e+00]] Access Granted From the printout we can see that the prediction for value four is equal to 1.0 and all the other values are either zero or extremely small. And of course we get ‚ÄúAccess Granted‚Äù üòÑ\n","date":1575055024,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575055024,"objectID":"29c838f9915b92f5ad6acabb0a646a46","permalink":"https://mariarigaki.github.io/post/hacking-nn-programmatically/","publishdate":"2019-11-29T20:17:04+01:00","relpermalink":"/post/hacking-nn-programmatically/","section":"post","summary":"TL;DR Using Tensorflow / Keras APIs to read and change Neural Network parameters.\nA few days ago I came across a paper called ‚ÄúHacking Neural Networks‚Äù by Michael Kissner aka @Spellwrath. It is a beautiful introduction to attacks against neural networks, very approachable and fun to read. What I liked most is that it comes together with a Github repository and some exercises to try the different attacks: https://github.com/Kayzaks/HackingNeuralNetworks\nThe first chapter introduces a simple attack where the main idea is that we want to cause a neural network to misclassify an image by just changing some part of the model.","tags":[],"title":"Changing Weights and Biases Programmatically for ‚ÄúNeural Network Hacking‚Äù and more","type":"post"},{"authors":["Maria Rigaki","Elnaz Babayeva","Sebastian Garcia"],"categories":[],"content":"","date":1572548732,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572548732,"objectID":"c2d57981308e3561d74308cd70e6f8ec","permalink":"https://mariarigaki.github.io/talk/cybersecai/","publishdate":"2019-10-31T20:05:32+01:00","relpermalink":"/talk/cybersecai/","section":"talk","summary":"It is well known in the machine learning community that the performance of models degrades over time with the introduction of new data, getting worse in solving both new and old tasks. This is also true for security applications of machine learning, but there is less knowledge of how this happens, when, and why. In the particular case of malware classification, the increasing growth in the amount of malicious files forces the community to research machine learning models that use data more effectively. Inspired by the way humans learn, Continual Learning algorithms try to incrementally learn new tasks from data that keeps changing, without forgetting the tasks learned in the past. In this talk we will try to address the following questions: Is Continual Learning a suitable approach for security-related datasets and problems? Can Continual Learning methods learn new malware families effectively without forgetting old ones? What are the improvements in terms of speed and storage?","tags":[],"title":"Forget me not: Malware Classification as a Continual Learning Problem","type":"talk"},{"authors":["Veronica Valeros","Maria Rigaki","Kamila Babayeva","Sebastian Garcia"],"categories":[],"content":"","date":1570147200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570643815,"objectID":"60b434fc20e72e5cdfadeafed03cf64e","permalink":"https://mariarigaki.github.io/talk/virusb2019/","publishdate":"2019-10-04T00:00:00Z","relpermalink":"/talk/virusb2019/","section":"talk","summary":"Reports on cyber espionage operations have been on the rise in the last decade. However, operations in Latin America are heavily under researched and potentially underestimated. In this paper we analyse and dissect a cyber espionage tool known as Machete. The results presented in this work are based on the collection, reversing and analysis of Machete samples from 2013 to 2019. The large collection of samples allowed us to analyse changes in features and the malware's evolution, including the latest changes introduced in January 2019.\nOur research shows that Machete is operated by a highly coordinated and organized group that focuses on Latin American targets. We describe the five phases of the APT operations from delivery to exfiltration of information and we show why Machete is considered a cyber espionage tool. Furthermore, our analysis indicates that the targeted victims belong to military, political or diplomatic sectors. The review of the almost six years of Machete operations shows that it is likely operated by a single group, and their activities are possibly state-sponsored. Machete is still active and operational to this day.","tags":[],"title":"Virus Bulletin 2019","type":"talk"},{"authors":["Maria Rigaki"],"categories":["hackathon","side-channels"],"content":"TL;DR Using a Picoscope 2204A and its SDK to perform timing side channel attacks against a weak password checker implementation running in an Arduino. Code, screenshots and lessons learned!\nLast weekend we held the bi-annual Stratosphere hackathon. It is a small tradition where twice a year the whole team gathers in a relatively remote place and we spend the weekend hacking and bonding. This time the hackathon was held at the beautiful Mal√° √öpa, in the mountains close to the border of Czech Republic and Poland.\n  Our hackathon home   The goal For this year\u0026rsquo;s event I decided that I wanted to work on something that I had not done before and step quite a lot out of my comfort zone. Ever since the Real World Crypto summer school that I attended this year in Croatia and the Side Channel Attacks (SCA) workshop, I\u0026rsquo;ve been meaning to work on side channels. In addition I had not really used an oscilloscope before and that was an opportunity to learn more and get over the fear and mystery of hardware.\nStarting out, my goal for the hackathon was to learn how to use a USB based oscilloscope and use it in order to perform side channel attacks. The weapon of choice was a Picoscope 2204A [1] which was chosen based on the following criteria: a) it is a USB scope so it is easy to carry and works with my laptop, b) it is relatively reliable and while it is the entry level product of the series, it still is quite powerfull and c) it has software that runs in all platforms and more specifically Linux. This was crucial since I did not want to fiddle around with Windows or scopes that did not offer a good software solution including SDKs.\nSide Channel Attack (SCA) Side channel attacks are attacks that take advantage of information leakage that is not directly related to the function being attacked. For example, in cryptography you might have a cryptographic function such a smart card or other software that performs communication encryption. A side channel is using information such as power analysis, timing, electromagentic emanations, sound, etc to reveal secret keys instead of attacking the cryptographic algorithm itself.\nA timing side-channel I started first with a simple kind of SCA which is a timing attack against an insecure password implementation. I found a nice blog explaining timing side channel attacks in Arduino [2] and I used the arduino code provided there, as the vulnerable implementation to attack:   Arduino code from [2]   The main idea is that you store a six digit password (or any length really) and you use the serial port to send a candidate password to the Arduino. While the Arduino checks the password it turns on a LED that in essence corresponds to a digital pin set to ON. The password checking implementation looks at one digit at a time but it returns as soon as an incorrect digit is found. The fact that the response is not constant in time means that it leaks information about the validity of each digit, rendering the timing attack possible. Using the fact that the LED pin is turned on while the password check is perfomed, we can monitor the time that the PIN is on using the oscilloscope. The more digits that are correct, the longer the password checker takes and the longer the LED pin is on.\nTo illustrate the problem let\u0026rsquo;s see how the Picoscope software looks like when the first 3 digits are correct:   First three correct digits   and when all 6 digits are correct:   All digits correct   Using the Picoscope The Picoscope is a USB oscilloscope that can be used for multiple purposes such as voltage measurement, spectrum analysis, serial channel decoding, etc. The interesting thing about USB scopes is that they come with powerful software that can perform advanced measurements and calculations which are usually quite expensive to get, or cost extra in bigger tabletop oscilloscopes. Of course it all comes down to specifications such as sampling rates, bandwidth, number of channels and so on, but my impression so far is that you can get very good value for money with a good USB scope.\nI do not intent to cover the Picoscope functions in detail in this blog post, but I do want to mention two functions that were important for this project: Triggers and automatic measurement functions.\nAs the scope runs, it continuously gathers data until you stop it. This results in viewing everything on screen in real time but usually we want to \u0026ldquo;freeze\u0026rdquo; the scope when something of interest happens so that we can see it. A trigger allows us to tell the scope when to start (and stop) capturing data and present them on screen. Triggers can be single (only triggers once) or repeated (when we capturing periodic events) and they come with a lot of settings such as rising edge or falling edge, etc. An example of a rising edge trigger is when we want the scope to start capturing when the voltage of a measurement goes from 0 to some higher value.\nThe other function that I used a lot in this project was the measurement functionality. Since we want to measure the time for which the LED pin is on we can use the high pulse width type of measurement. The results appear as a line in the bottom of the window and it is visible in the previous two pictures.\nUsing the Pico SDK to perform the attack Since we can access the serial port we could always perform the attack programmatically, for example using pyserial. But where is the fun in that? üòÑ Besides, I wanted to use the scope for the attack, since the fact that the serial port was used for input was just for illustration purposes. It could have been replaced just as easily with a bunch of buttons or some other way to provide input that is not directly measurable.\nIt was also a great opportunity to learn how to use the SDK that comes with the Picoscope. After looking at the site for documentation I got to the Github link where all the SDK software can be found [3]. A good number of languages is supported (C/C++, C#, Python, VB .NET, LabVIEW, MATLAB). For each language and each specific driver there is example code that helps to get started. Although the code is very well documented and the programming guide explains quite a few details, the task was not problem free.\nThe first problem I faced was that I could not open the port and connect to the device. It turns out that there are two drivers for the 2000 series: the ps2000 and the ps2000a. Although my device is called 2204A it actually did NOT use the ps2000a driver but the ps2000 one. I found that out after going through some posts in the support forum that faced similar problems. Even though I knew now which example should be the correct one to try, I still could not connect to the device. It turned out that I needed to run the python script using sudo in order to open the connection!!!\nThe second problem was to reproduce the settings that were working with the picoscope using the python code. The most straight forward approach here was to try and understand the different API calls and how they correspond to the software settings and then plot the screens using matplotlib in order to see the captured data. After fiddling quite a bit with the code I managed to produce something like the folllowing which is very close to what I could see in the picoscope software after providing the correct password:   All digits correct using the SDK   Code walkthrough As a base I started with the Block code example that comes with the SDK. As mentioned in the example, the code \u0026ldquo;opens a 2000 driver device, sets up two channels and a trigger then collects a block of data. This data is then plotted as mV against time in ns.\u0026rdquo; Steps:\n Open connection: ps2000_open_unit() Define channels: ps2000_set_channel() Define triggers: ps2000_set_trigger() Get timebase information: ps2000_get_timebase() Capture data: ps2000_run_block() Check if data collection is finished: ps2000_ready() Get the data from the scope: ps2000_get_values() Convert data from ADC to mV: adc2mV() Plot the data using matplotlib: plt.plot() Stop the scope: ps2000_stop() Close the scope: ps2000_close_unit()  Defining the trigger and the timebase were the most challenging parts for me, because the way some things are defined were not exactly similar to what I was seeing using the picoscope software. For example, the trigger threshold was set using ADC counts and not in voltage as it was on the software. The timebase was also tricky because it expects an integer value that is relative to the maximum timebase your device supports. After some calculations and a bit of trial and error, I managed to get to a point where my captured data corresponded to something I could use for the attack. The programming guide that explains the functions and their arguments in detail can be found here [4].\nThe following changes/additions were required for the timing attack:\n Open the serial port using pyserial. Send a password while data capture was running. Instead of plotting measure how many data points are above 490mV. Keep the maximum value and digit as a candidate digit. Repeat for all possible digits (0\u0026hellip;9). Repeat for all six digits of the password.  The gist with all the code can be found here [5] and a screenshot of the ouptut can be seen here:   All digits correct   Summary I really enjoyed this project and it turned out that this was a great fit for the hackathon as I managed to pull it off within the 24 hour period that we had for this. Before I started out, I had very little experience using an oscilloscope and I only watched some videos in Youtube in order to try and learn the basics. Now, I feel much more comfortable and I am looking forward to explore more capabilities of the scope. Hopefully I will be able to use it to perform other types of side channels. Stay tuned and as always if you have any questions or comments feel free to contact me!\nLinks and References [1] https://www.picotech.com/oscilloscope/2000/picoscope-2000-overview\n[2] http://eax64.github.io/2015/04/10/timing-attack-on-arduino.html\n[3] https://github.com/picotech\n[4] https://www.picotech.com/download/manuals/picoscope-2000-series-programmers-guide.pdf\n[5] https://gist.github.com/MariaRigaki/2d65a8a569cced23272beb7962d6654d\n","date":1564398965,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564398965,"objectID":"a0bf076b92406ca1073feaa1016cbfe7","permalink":"https://mariarigaki.github.io/post/summer-hacakathon-2019/","publishdate":"2019-07-29T13:16:05+02:00","relpermalink":"/post/summer-hacakathon-2019/","section":"post","summary":"TL;DR Using a Picoscope 2204A and its SDK to perform timing side channel attacks against a weak password checker implementation running in an Arduino. Code, screenshots and lessons learned!\nLast weekend we held the bi-annual Stratosphere hackathon. It is a small tradition where twice a year the whole team gathers in a relatively remote place and we spend the weekend hacking and bonding. This time the hackathon was held at the beautiful Mal√° √öpa, in the mountains close to the border of Czech Republic and Poland.","tags":["side-channels","oscilloscope"],"title":"Scoping it out!","type":"post"},{"authors":["Veronica Valeros","Maria Rigaki","Sebastian Garcia"],"categories":["conference paper"],"content":"","date":1561024587,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553162187,"objectID":"88e4dade1d12f9b12d5272afa31d375e","permalink":"https://mariarigaki.github.io/publication/machete/","publishdate":"2019-06-20T11:56:27+02:00","relpermalink":"/publication/machete/","section":"publication","summary":"Reports on cyber espionage operations have been on the rise in the last decade. However, operations in Latin America are heavily under researched and potentially underestimated. In this paper we analyze and dissect a cyber espionage tool known as Machete. Our research shows that Machete is operated by a highly coordinated and organized group who focuses on Latin American targets. We describe the five phases of the APT operations from delivery to exfiltration of information and we show why Machete is considered a cyber espionage tool. Furthermore, our analysis indicates that the targeted victims belong to military, political, or diplomatic sectors. The review of almost six years of Machete operations show that it is likely operated by a single group, and their activities are possibly statesponsored. Machete is still active and operational to this day","tags":["advanced persistence threat","cyber espionage","malware operations"],"title":"Machete: Dissecting the Operations of a Cyber Espionage Group in Latin America","type":"publication"},{"authors":["Maria Rigaki","Sebastian Garcia"],"categories":["conference paper"],"content":"","date":1527069387,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527069387,"objectID":"3d3cbdada8e20df7b08a56976bf713b9","permalink":"https://mariarigaki.github.io/publication/gan-knife-fight/","publishdate":"2018-05-23T11:56:27+02:00","relpermalink":"/publication/gan-knife-fight/","section":"publication","summary":"Generative Adversarial Networks (GANs) have been successfully used in a large number of domains. This paper proposes the use of GANs for generating network traffic in order to mimic other types of traffic. In particular, our method modifies the network behavior of a real malware in order to mimic the traffic of a legitimate application, and therefore avoid detection. By modifying the source code of a malware to receive parameters from a GAN, it was possible to adapt the behavior of its Command and Control (C2) channel to mimic the behavior of Facebook chat network traffic. In this way, it was possible to avoid the detection of new-generation Intrusion Prevention Systems that use machine learning and behavioral characteristics. A real-life scenario was successfully implemented using the Stratosphere behavioral IPS in a router, while the malware and the GAN were deployed in the local network of our laboratory, and the C2 server was deployed in the cloud. Results show that a GAN can successfully modify the traffic of a malware to make it undetectable. The modified malware also tested if it was being blocked and used this information as a feedback to the GAN. This work envisions the possibility of self-adapting malware and self-adapting IPS.","tags":["GAN","intrusion detection"],"title":"Bringing a GAN to a Knife-fight: Adapting Malware Communication to Avoid Detection","type":"publication"},{"authors":["Maria Rigaki"],"categories":[],"content":"","date":1523059200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560426163,"objectID":"0796ec4dd08a290e275c4cce7c8c5b5c","permalink":"https://mariarigaki.github.io/talk/arming/","publishdate":"2018-04-07T00:00:00Z","relpermalink":"/talk/arming/","section":"talk","summary":"Generative Adversarial Networks (GANs) are a recent invention that shows impressive results in generating completely new images of faces, building interiors and much more. In this talk we present how we can use GANs to modify network traffic parameters in order to mimic other types of traffic. More specifically, we modify an open source malware to use a GAN to dynamically adapt its Command and Control network behavior and mimic the traffic characteristics of Facebook chat. In this way it is able to avoid the detection from new-generation Intrusion Prevention Systems that use behavioral characteristics. We will present our experiments from a real-life scenario that used the Stratosphere behavioral IPS deployed in a router between the malware which was deployed in our lab and the C\u0026C server deployed in AWS. Results show that it is possible for the malware to become undetected when given the input parameters from a GAN. The malware is also aware of whether or not it is being blocked and uses this as a feedback signal in order to improve the GAN model. Finally, we discuss the implications of this work in malware detection as well as other areas such as censorship circumvention.","tags":[],"title":"Arming Malware with GANs","type":"talk"},{"authors":["Maria Rigaki"],"categories":["thesis"],"content":"","date":1499334185,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499334185,"objectID":"d189106c8eed5be708b32abf10a6ae0c","permalink":"https://mariarigaki.github.io/publication/master-thesis/","publishdate":"2017-07-06T11:43:05+02:00","relpermalink":"/publication/master-thesis/","section":"publication","summary":"Traditional approaches in network intrusion detection follow a signature-based ap- proach, however the use of anomaly detection approaches based on machine learning techniques have been studied heavily for the past twenty years. The continuous change in the way attacks are appearing, the volume of attacks, as well as the improvements in the big data analytics space, make machine learning approaches more alluring than ever. The intention of this thesis is to show that using machine learning in the intrusion detection domain should be accompanied with an evaluation of its robustness against adversaries. Several adversarial techniques have emerged lately from the deep learning research, largely in the area of image classification. These techniques are based on the idea of introducing small changes in the original input data in order to make a machine learning model to misclassify it. This thesis follows a big data Analytics methodology and explores adversarial machine learning techniques that have emerged from the deep learning domain, against machine learning classifiers used for network intrusion detection. The study looks at several well known classifiers and studies their performance under attack over several metrics, such as accuracy, F1-score and receiver operating characteristic. The approach used assumes no knowledge of the original classifier and examines both general and targeted misclassification. The results show that using relatively simple methods for generating adversarial samples it is possible to lower the detection accuracy of intrusion detection classifiers from 5% to 28%. Performance degradation is achieved using a methodology that is simpler than previous approaches and it requires only 6.25% change between the original and the adversarial sample, making it a candidate for a practical adversarial approach.","tags":["adversarial ml","intrusion detection"],"title":"Adversarial Deep Learning Against Intrusion Detection Classifiers","type":"publication"}]