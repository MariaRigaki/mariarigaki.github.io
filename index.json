[{"authors":["admin"],"categories":null,"content":"Maria Rigaki is a PhD student in the department of Computer Science at Czech Technical University (CTU) in Prague. As a member of Stratosphere Lab, she is working on applications of Machine Learning and AI in cyber security. Before that she spent many years working as a software developer and systems architect. Her work spanned several domains including designing and developing solutions for telecommunications, physical security, emergency response systems and critical infrastructures. In her spare time Maria enjoys hacking and playing CTFs.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://mariarigaki.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Maria Rigaki is a PhD student in the department of Computer Science at Czech Technical University (CTU) in Prague. As a member of Stratosphere Lab, she is working on applications of Machine Learning and AI in cyber security. Before that she spent many years working as a software developer and systems architect. Her work spanned several domains including designing and developing solutions for telecommunications, physical security, emergency response systems and critical infrastructures.","tags":null,"title":"Maria Rigaki","type":"authors"},{"authors":["Veronica Valeros","Maria Rigaki","Sebastian Garcia"],"categories":["conference paper"],"content":"","date":1561024587,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553162187,"objectID":"88e4dade1d12f9b12d5272afa31d375e","permalink":"https://mariarigaki.github.io/publication/machete/","publishdate":"2019-06-20T11:56:27+02:00","relpermalink":"/publication/machete/","section":"publication","summary":"Reports on cyber espionage operations have been on the rise in the last decade. However, operations in Latin America are heavily under researched and potentially underestimated. In this paper we analyze and dissect a cyber espionage tool known as Machete. Our research shows that Machete is operated by a highly coordinated and organized group who focuses on Latin American targets. We describe the five phases of the APT operations from delivery to exfiltration of information and we show why Machete is considered a cyber espionage tool. Furthermore, our analysis indicates that the targeted victims belong to military, political, or diplomatic sectors. The review of almost six years of Machete operations show that it is likely operated by a single group, and their activities are possibly statesponsored. Machete is still active and operational to this day","tags":["advanced persistence threat","cyber espionage","malware operations"],"title":"Machete: Dissecting the Operations of a Cyber Espionage Group in Latin America","type":"publication"},{"authors":["Maria Rigaki","Sebastian Garcia"],"categories":["conference paper"],"content":"","date":1527069387,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527069387,"objectID":"3d3cbdada8e20df7b08a56976bf713b9","permalink":"https://mariarigaki.github.io/publication/gan-knife-fight/","publishdate":"2018-05-23T11:56:27+02:00","relpermalink":"/publication/gan-knife-fight/","section":"publication","summary":"Generative Adversarial Networks (GANs) have been successfully used in a large number of domains. This paper proposes the use of GANs for generating network traffic in order to mimic other types of traffic. In particular, our method modifies the network behavior of a real malware in order to mimic the traffic of a legitimate application, and therefore avoid detection. By modifying the source code of a malware to receive parameters from a GAN, it was possible to adapt the behavior of its Command and Control (C2) channel to mimic the behavior of Facebook chat network traffic. In this way, it was possible to avoid the detection of new-generation Intrusion Prevention Systems that use machine learning and behavioral characteristics. A real-life scenario was successfully implemented using the Stratosphere behavioral IPS in a router, while the malware and the GAN were deployed in the local network of our laboratory, and the C2 server was deployed in the cloud. Results show that a GAN can successfully modify the traffic of a malware to make it undetectable. The modified malware also tested if it was being blocked and used this information as a feedback to the GAN. This work envisions the possibility of self-adapting malware and self-adapting IPS.","tags":["GAN","intrusion detection"],"title":"Bringing a GAN to a Knife-fight: Adapting Malware Communication to Avoid Detection","type":"publication"},{"authors":["Maria Rigaki"],"categories":[],"content":"","date":1523059200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560426163,"objectID":"0796ec4dd08a290e275c4cce7c8c5b5c","permalink":"https://mariarigaki.github.io/talk/arming/","publishdate":"2018-04-07T00:00:00Z","relpermalink":"/talk/arming/","section":"talk","summary":"Generative Adversarial Networks (GANs) are a recent invention that shows impressive results in generating completely new images of faces, building interiors and much more. In this talk we present how we can use GANs to modify network traffic parameters in order to mimic other types of traffic. More specifically, we modify an open source malware to use a GAN to dynamically adapt its Command and Control network behavior and mimic the traffic characteristics of Facebook chat. In this way it is able to avoid the detection from new-generation Intrusion Prevention Systems that use behavioral characteristics. We will present our experiments from a real-life scenario that used the Stratosphere behavioral IPS deployed in a router between the malware which was deployed in our lab and the C\u0026C server deployed in AWS. Results show that it is possible for the malware to become undetected when given the input parameters from a GAN. The malware is also aware of whether or not it is being blocked and uses this as a feedback signal in order to improve the GAN model. Finally, we discuss the implications of this work in malware detection as well as other areas such as censorship circumvention.","tags":[],"title":"Arming Malware with GANs","type":"talk"},{"authors":["Maria Rigaki"],"categories":["thesis"],"content":"","date":1499334185,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1499334185,"objectID":"d189106c8eed5be708b32abf10a6ae0c","permalink":"https://mariarigaki.github.io/publication/master-thesis/","publishdate":"2017-07-06T11:43:05+02:00","relpermalink":"/publication/master-thesis/","section":"publication","summary":"Traditional approaches in network intrusion detection follow a signature-based ap- proach, however the use of anomaly detection approaches based on machine learning techniques have been studied heavily for the past twenty years. The continuous change in the way attacks are appearing, the volume of attacks, as well as the improvements in the big data analytics space, make machine learning approaches more alluring than ever. The intention of this thesis is to show that using machine learning in the intrusion detection domain should be accompanied with an evaluation of its robustness against adversaries. Several adversarial techniques have emerged lately from the deep learning research, largely in the area of image classification. These techniques are based on the idea of introducing small changes in the original input data in order to make a machine learning model to misclassify it. This thesis follows a big data Analytics methodology and explores adversarial machine learning techniques that have emerged from the deep learning domain, against machine learning classifiers used for network intrusion detection. The study looks at several well known classifiers and studies their performance under attack over several metrics, such as accuracy, F1-score and receiver operating characteristic. The approach used assumes no knowledge of the original classifier and examines both general and targeted misclassification. The results show that using relatively simple methods for generating adversarial samples it is possible to lower the detection accuracy of intrusion detection classifiers from 5% to 28%. Performance degradation is achieved using a methodology that is simpler than previous approaches and it requires only 6.25% change between the original and the adversarial sample, making it a candidate for a practical adversarial approach.","tags":["adversarial ml","intrusion detection"],"title":"Adversarial Deep Learning Against Intrusion Detection Classifiers","type":"publication"}]